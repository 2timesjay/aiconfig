{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EQ-Ib1609n-O",
        "outputId": "5ff76b60-a16a-4bc1-9a4f-987c6b732564"
      },
      "outputs": [],
      "source": [
        "# !pip install openai python-aiconfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru_ujtI_-M8y",
        "outputId": "15532497-87bb-4057-c4b3-b79d4d02d474"
      },
      "outputs": [],
      "source": [
        "# import openai\n",
        "# import aiconfig\n",
        "# from google.colab import userdata\n",
        "# openai.api_key = userdata.get('OPENAI_API_KEY')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Non-Colab\n",
        "import json\n",
        "import openai\n",
        "openai.api_key = open(\"/home/jacobjensen/secrets/openai_api_key.txt\", \"r\").read().strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxkHKfMLbTLN"
      },
      "source": [
        "## Function Calling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "x6rFM3Vpcs-D"
      },
      "outputs": [],
      "source": [
        "from pydantic import create_model\n",
        "from typing import Callable, Dict, List\n",
        "import inspect, json\n",
        "from inspect import Parameter\n",
        "def sums(a:int, b:int=1):\n",
        "    \"Adds a + b\"\n",
        "    return a + b\n",
        "def schema(f):\n",
        "    kw = {n:(o.annotation, ... if o.default==Parameter.empty else o.default)\n",
        "          for n,o in inspect.signature(f).parameters.items()}\n",
        "    s = create_model(f'Input for `{f.__name__}`', **kw).schema()\n",
        "    return dict(name=f.__name__, description=f.__doc__, parameters=s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZST3nyXJbwEs"
      },
      "outputs": [],
      "source": [
        "def inject_function_call_spec(functions: List[Callable]):\n",
        "    spec = json.load(open(\"function_calling_list_builder_aiconfig.json\", 'r'))\n",
        "    spec[\"prompts\"][0][\"metadata\"][\"model\"][\"settings\"][\"functions\"] = [schema(f) for f in functions]\n",
        "    return spec\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def initialize_list(items: List[str]) -> List[str]:\n",
        "    \"\"\"returns an initial list of items\"\"\"\n",
        "    return items\n",
        "\n",
        "async def add_to_list(li: List[str], items: List[str]) -> List[str]:\n",
        "    \"\"\"returns a list with items added, does not add duplicates\"\"\"\n",
        "    return li + [item for item in items if item not in set(li)]\n",
        "\n",
        "async def remove_from_list(li: List[str], items: List[str]) -> List[str]:\n",
        "    \"\"\"returns a list with items removed\"\"\"\n",
        "    return [item for item in li if item not in set(items)]\n",
        "\n",
        "# Note - this function isn't about calling an API or mutating state, but about enforcing an output format for assessments\n",
        "async def assess_list(li: List[str], assessment: Dict[str, str]) -> List[str]: \n",
        "    \"\"\"Accepts a dictionary of assessments of a list, keyed by the name of characteristic being assessed.\"\"\"\n",
        "    return assessment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "fBN7ETp6bV5o"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import json\n",
        "import uuid\n",
        "from aiconfig import AIConfigRuntime\n",
        "from aiconfig import PromptInput\n",
        "from aiconfig.model_parser import InferenceOptions\n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "async def function_calling(function_list):\n",
        "    function_call_spec = inject_function_call_spec(function_list)\n",
        "    function_dict = {f.__name__: f for f in function_list}\n",
        "    config = AIConfigRuntime.create(**function_call_spec)\n",
        "    return config, function_dict\n",
        "\n",
        "async def call_function(function_call, function_dict):\n",
        "    args = function_call.get(\"arguments\", None)\n",
        "    args = json.loads(args) if args else None\n",
        "\n",
        "    if not args:\n",
        "        raise Exception(\"No arguments found\")\n",
        "\n",
        "    function = function_dict.get(function_call[\"name\"], None)\n",
        "    if not function:\n",
        "        raise Exception(f\"Function {function_call['name']} not found\")\n",
        "    else:\n",
        "        return await function(**args)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_496394/3314632738.py:11: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
            "  s = create_model(f'Input for `{f.__name__}`', **kw).schema()\n"
          ]
        }
      ],
      "source": [
        "config, function_dict = await function_calling([initialize_list, add_to_list, remove_from_list, assess_list])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'functions': [{'name': 'initialize_list',\n",
              "   'description': 'returns an initial list of items',\n",
              "   'parameters': {'properties': {'items': {'items': {'type': 'string'},\n",
              "      'title': 'Items',\n",
              "      'type': 'array'}},\n",
              "    'required': ['items'],\n",
              "    'title': 'Input for `initialize_list`',\n",
              "    'type': 'object'}},\n",
              "  {'name': 'add_to_list',\n",
              "   'description': 'returns a list with items added, does not add duplicates',\n",
              "   'parameters': {'properties': {'li': {'items': {'type': 'string'},\n",
              "      'title': 'Li',\n",
              "      'type': 'array'},\n",
              "     'items': {'items': {'type': 'string'},\n",
              "      'title': 'Items',\n",
              "      'type': 'array'}},\n",
              "    'required': ['li', 'items'],\n",
              "    'title': 'Input for `add_to_list`',\n",
              "    'type': 'object'}},\n",
              "  {'name': 'remove_from_list',\n",
              "   'description': 'returns a list with items removed',\n",
              "   'parameters': {'properties': {'li': {'items': {'type': 'string'},\n",
              "      'title': 'Li',\n",
              "      'type': 'array'},\n",
              "     'items': {'items': {'type': 'string'},\n",
              "      'title': 'Items',\n",
              "      'type': 'array'}},\n",
              "    'required': ['li', 'items'],\n",
              "    'title': 'Input for `remove_from_list`',\n",
              "    'type': 'object'}},\n",
              "  {'name': 'assess_list',\n",
              "   'description': 'Accepts a dictionary of assessments of a list, keyed by the name of characteristic being assessed.',\n",
              "   'parameters': {'properties': {'li': {'items': {'type': 'string'},\n",
              "      'title': 'Li',\n",
              "      'type': 'array'},\n",
              "     'assessment': {'additionalProperties': {'type': 'string'},\n",
              "      'title': 'Assessment',\n",
              "      'type': 'object'}},\n",
              "    'required': ['li', 'assessment'],\n",
              "    'title': 'Input for `assess_list`',\n",
              "    'type': 'object'}}],\n",
              " 'model': 'gpt-3.5-turbo',\n",
              " 'messages': [{'content': 'You are helping to make a shopping list for a user.  Please use functions to manage the list.',\n",
              "   'role': 'system'},\n",
              "  {'content': 'Current list state: [], current query: I want to buy supplies for a 15 mile hike in hot weather.',\n",
              "   'role': 'user'}]}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_input = \"I want to buy supplies for a 15 mile hike in hot weather.\"\n",
        "li = []\n",
        "promptToRun = \"recommendList\"\n",
        "inference_options = InferenceOptions(stream=True)\n",
        "\n",
        "async def run_chat(user_input, li, promptToRun=promptToRun, inference_options=inference_options):\n",
        "    params = {\n",
        "        \"user_input\": user_input,\n",
        "        \"list\": li,\n",
        "    }\n",
        "    output = await config.run(promptToRun, params, inference_options)\n",
        "    return output\n",
        "\n",
        "\n",
        "await config.resolve(prompt_name=\"recommendList\", params={\"user_input\": user_input, \"list\": li})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output_type='execute_result' execution_count=0 data={'function_call': {'arguments': '{\\n  \"items\": [\"water\", \"snacks\", \"sunscreen\", \"hat\", \"sunglasses\", \"hiking boots\"]\\n}', 'name': 'initialize_list'}, 'role': 'assistant'} mime_type=None metadata={'finish_reason': 'function_call'}\n",
            "['water', 'snacks', 'sunscreen', 'hat', 'sunglasses', 'hiking boots']\n",
            "{'role': 'function', 'name': 'initialize_list', 'content': '[\"water\", \"snacks\", \"sunscreen\", \"hat\", \"sunglasses\", \"hiking boots\"]'}\n",
            "\n",
            "output_type='execute_result' execution_count=0 data={'function_call': {'arguments': '{\\n  \"li\": [\"water\", \"snacks\", \"sunscreen\", \"hat\", \"sunglasses\", \"hiking boots\"],\\n  \"items\": [\"backpack\", \"map\", \"compass\", \"first aid kit\", \"extra clothing\"]\\n}', 'name': 'add_to_list'}, 'role': 'assistant'} mime_type=None metadata={'finish_reason': 'function_call'}\n",
            "['water', 'snacks', 'sunscreen', 'hat', 'sunglasses', 'hiking boots', 'backpack', 'map', 'compass', 'first aid kit', 'extra clothing']\n",
            "{'role': 'function', 'name': 'add_to_list', 'content': '[\"water\", \"snacks\", \"sunscreen\", \"hat\", \"sunglasses\", \"hiking boots\", \"backpack\", \"map\", \"compass\", \"first aid kit\", \"extra clothing\"]'}\n",
            "\n",
            "output_type='execute_result' execution_count=0 data={'function_call': {'arguments': '{\\n  \"li\": [\"water\", \"snacks\", \"sunscreen\", \"hat\", \"sunglasses\", \"hiking boots\", \"backpack\", \"map\", \"compass\", \"first aid kit\", \"extra clothing\"]\\n}', 'name': 'assess_list'}, 'role': 'assistant'} mime_type=None metadata={'finish_reason': 'function_call'}\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "assess_list() missing 1 required positional argument: 'assessment'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/jacobjensen/Projects/llms/aiconfig/cookbooks/Function-Calling-and-Trace-Generation/function_calling_and_trace_generation.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jacobjensen/Projects/llms/aiconfig/cookbooks/Function-Calling-and-Trace-Generation/function_calling_and_trace_generation.ipynb#X31sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jacobjensen/Projects/llms/aiconfig/cookbooks/Function-Calling-and-Trace-Generation/function_calling_and_trace_generation.ipynb#X31sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# If there is a function call, we generate a new message with the role 'function'.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jacobjensen/Projects/llms/aiconfig/cookbooks/Function-Calling-and-Trace-Generation/function_calling_and_trace_generation.ipynb#X31sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m call_function(message\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mfunction_call\u001b[39m\u001b[39m\"\u001b[39m), function_dict)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jacobjensen/Projects/llms/aiconfig/cookbooks/Function-Calling-and-Trace-Generation/function_calling_and_trace_generation.ipynb#X31sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mprint\u001b[39m(result)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jacobjensen/Projects/llms/aiconfig/cookbooks/Function-Calling-and-Trace-Generation/function_calling_and_trace_generation.ipynb#X31sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m new_message \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jacobjensen/Projects/llms/aiconfig/cookbooks/Function-Calling-and-Trace-Generation/function_calling_and_trace_generation.ipynb#X31sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mfunction\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jacobjensen/Projects/llms/aiconfig/cookbooks/Function-Calling-and-Trace-Generation/function_calling_and_trace_generation.ipynb#X31sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: message[\u001b[39m\"\u001b[39m\u001b[39mfunction_call\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jacobjensen/Projects/llms/aiconfig/cookbooks/Function-Calling-and-Trace-Generation/function_calling_and_trace_generation.ipynb#X31sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: json\u001b[39m.\u001b[39mdumps(result),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jacobjensen/Projects/llms/aiconfig/cookbooks/Function-Calling-and-Trace-Generation/function_calling_and_trace_generation.ipynb#X31sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m }\n",
            "\u001b[1;32m/home/jacobjensen/Projects/llms/aiconfig/cookbooks/Function-Calling-and-Trace-Generation/function_calling_and_trace_generation.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jacobjensen/Projects/llms/aiconfig/cookbooks/Function-Calling-and-Trace-Generation/function_calling_and_trace_generation.ipynb#X31sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFunction \u001b[39m\u001b[39m{\u001b[39;00mfunction_call[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m not found\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jacobjensen/Projects/llms/aiconfig/cookbooks/Function-Calling-and-Trace-Generation/function_calling_and_trace_generation.ipynb#X31sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jacobjensen/Projects/llms/aiconfig/cookbooks/Function-Calling-and-Trace-Generation/function_calling_and_trace_generation.ipynb#X31sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mawait\u001b[39;00m function(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49margs)\n",
            "\u001b[0;31mTypeError\u001b[0m: assess_list() missing 1 required positional argument: 'assessment'"
          ]
        }
      ],
      "source": [
        "\n",
        "while True:\n",
        "    model_output = await run_chat(user_input, li, promptToRun, inference_options)\n",
        "\n",
        "    output = model_output[0] if isinstance(model_output, list) else model_output\n",
        "    print(output)\n",
        "\n",
        "    if output.output_type == \"error\":\n",
        "        raise ValueError(f\"Error during inference: {output.ename}: {output.evalue}\")\n",
        "\n",
        "    message = output.data\n",
        "\n",
        "    # If there is no function call, we're done and can exit this loop\n",
        "    if not message.get(\"function_call\", None):\n",
        "        print(\"No function call found\")\n",
        "        break\n",
        "\n",
        "    # If there is a function call, we generate a new message with the role 'function'.\n",
        "\n",
        "    result = await call_function(message.get(\"function_call\"), function_dict)\n",
        "    print(result)\n",
        "\n",
        "    new_message = {\n",
        "        \"role\": \"function\",\n",
        "        \"name\": message[\"function_call\"][\"name\"],\n",
        "        \"content\": json.dumps(result),\n",
        "    }\n",
        "\n",
        "    promptToRun = f\"functionCallResult-{uuid.uuid4()}\"\n",
        "\n",
        "    existing_prompt = config.get_prompt(\"recommendList\")\n",
        "\n",
        "    new_prompt = copy.deepcopy(existing_prompt)\n",
        "    new_prompt.name = promptToRun\n",
        "    new_prompt.input = PromptInput(**new_message)\n",
        "    new_prompt.outputs = []\n",
        "\n",
        "    config.add_prompt(new_prompt.name, new_prompt)\n",
        "\n",
        "    print(f\"{new_message}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'functions': [{'name': 'initialize_list',\n",
              "   'description': 'returns an initial list of items',\n",
              "   'parameters': {'properties': {'items': {'items': {'type': 'string'},\n",
              "      'title': 'Items',\n",
              "      'type': 'array'}},\n",
              "    'required': ['items'],\n",
              "    'title': 'Input for `initialize_list`',\n",
              "    'type': 'object'}},\n",
              "  {'name': 'add_to_list',\n",
              "   'description': 'returns a list with items added, does not add duplicates',\n",
              "   'parameters': {'properties': {'li': {'items': {'type': 'string'},\n",
              "      'title': 'Li',\n",
              "      'type': 'array'},\n",
              "     'items': {'items': {'type': 'string'},\n",
              "      'title': 'Items',\n",
              "      'type': 'array'}},\n",
              "    'required': ['li', 'items'],\n",
              "    'title': 'Input for `add_to_list`',\n",
              "    'type': 'object'}},\n",
              "  {'name': 'remove_from_list',\n",
              "   'description': 'returns a list with items removed',\n",
              "   'parameters': {'properties': {'li': {'items': {'type': 'string'},\n",
              "      'title': 'Li',\n",
              "      'type': 'array'},\n",
              "     'items': {'items': {'type': 'string'},\n",
              "      'title': 'Items',\n",
              "      'type': 'array'}},\n",
              "    'required': ['li', 'items'],\n",
              "    'title': 'Input for `remove_from_list`',\n",
              "    'type': 'object'}},\n",
              "  {'name': 'assess_list',\n",
              "   'description': 'Accepts a dictionary of assessments of a list, keyed by the name of characteristic being assessed.',\n",
              "   'parameters': {'properties': {'li': {'items': {'type': 'string'},\n",
              "      'title': 'Li',\n",
              "      'type': 'array'},\n",
              "     'assessment': {'additionalProperties': {'type': 'string'},\n",
              "      'title': 'Assessment',\n",
              "      'type': 'object'}},\n",
              "    'required': ['li', 'assessment'],\n",
              "    'title': 'Input for `assess_list`',\n",
              "    'type': 'object'}}],\n",
              " 'model': 'gpt-3.5-turbo',\n",
              " 'messages': [{'content': 'You are helping to make a shopping list for a user.  Please use functions to manage the list.',\n",
              "   'role': 'system'},\n",
              "  {'content': 'Current list state: [&#x27;water&#x27;, &#x27;snacks&#x27;, &#x27;sunscreen&#x27;, &#x27;hat&#x27;, &#x27;sunglasses&#x27;, &#x27;hiking boots&#x27;, &#x27;backpack&#x27;, &#x27;map&#x27;, &#x27;compass&#x27;, &#x27;first aid kit&#x27;, &#x27;extra clothing&#x27;], current query: Thanks! can you trim this list to just 4 items?',\n",
              "   'role': 'user'},\n",
              "  {'function_call': {'arguments': '{\\n  \"items\": [\"water\", \"snacks\", \"sunscreen\", \"hat\", \"sunglasses\", \"hiking boots\"]\\n}',\n",
              "    'name': 'initialize_list'},\n",
              "   'role': 'assistant'}]}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_input = \"Thanks! can you trim this list to just 4 items?\"\n",
        "li = result\n",
        "await config.resolve(prompt_name=\"recommendList\", params={\"user_input\": user_input, \"list\": li})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "while True:\n",
        "    model_output = await run_chat(user_input, li, promptToRun, inference_options)\n",
        "\n",
        "    output = model_output[0] if isinstance(model_output, list) else model_output\n",
        "    print(output)\n",
        "\n",
        "    if output.output_type == \"error\":\n",
        "        raise ValueError(f\"Error during inference: {output.ename}: {output.evalue}\")\n",
        "\n",
        "    message = output.data\n",
        "\n",
        "    # If there is no function call, we're done and can exit this loop\n",
        "    if not message.get(\"function_call\", None):\n",
        "        print(\"No function call found\")\n",
        "        break\n",
        "\n",
        "    # If there is a function call, we generate a new message with the role 'function'.\n",
        "\n",
        "    result = await call_function(message.get(\"function_call\"), function_dict)\n",
        "\n",
        "    new_message = {\n",
        "        \"role\": \"function\",\n",
        "        \"name\": message[\"function_call\"][\"name\"],\n",
        "        \"content\": json.dumps(result),\n",
        "    }\n",
        "\n",
        "    promptToRun = f\"functionCallResult-{uuid.uuid4()}\"\n",
        "\n",
        "    existing_prompt = config.get_prompt(\"recommendList\")\n",
        "\n",
        "    new_prompt = copy.deepcopy(existing_prompt)\n",
        "    new_prompt.name = promptToRun\n",
        "    new_prompt.input = PromptInput(**new_message)\n",
        "    new_prompt.outputs = []\n",
        "\n",
        "    config.add_prompt(new_prompt.name, new_prompt)\n",
        "\n",
        "    print(f\"{new_message}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "emOUHVN2faSS",
        "outputId": "d708732a-644f-40fd-9ab1-cc8a0347d88c"
      },
      "outputs": [],
      "source": [
        "config.save(\"list_builder.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpDwvL9Biymr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
