{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EQ-Ib1609n-O",
        "outputId": "5ff76b60-a16a-4bc1-9a4f-987c6b732564"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.3.2-py3-none-any.whl (220 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.3/220.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-aiconfig\n",
            "  Downloading python_aiconfig-1.0.9-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Collecting requests==2.30.0 (from python-aiconfig)\n",
            "  Downloading requests-2.30.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting black (from python-aiconfig)\n",
            "  Downloading black-23.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flake8 (from python-aiconfig)\n",
            "  Downloading flake8-6.1.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from python-aiconfig) (7.4.3)\n",
            "Collecting pydantic<3,>=1.9.0 (from openai)\n",
            "  Downloading pydantic-2.5.1-py3-none-any.whl (381 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.6/381.6 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybars3 (from python-aiconfig)\n",
            "  Downloading pybars3-0.9.7.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting google-generativeai (from python-aiconfig)\n",
            "  Downloading google_generativeai-0.2.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv (from python-aiconfig)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting huggingface-hub (from python-aiconfig)\n",
            "  Downloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting result (from python-aiconfig)\n",
            "  Downloading result-0.14.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from python-aiconfig) (1.5.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.30.0->python-aiconfig) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.30.0->python-aiconfig) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.30.0->python-aiconfig) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.30.0->python-aiconfig) (2023.7.22)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Collecting httpcore (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
            "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Collecting pydantic-core==2.14.3 (from pydantic<3,>=1.9.0->openai)\n",
            "  Downloading pydantic_core-2.14.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions<5,>=4.5 (from openai)\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->python-aiconfig) (8.1.7)\n",
            "Collecting mypy-extensions>=0.4.3 (from black->python-aiconfig)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from black->python-aiconfig) (23.2)\n",
            "Collecting pathspec>=0.9.0 (from black->python-aiconfig)\n",
            "  Downloading pathspec-0.11.2-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->python-aiconfig) (3.11.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->python-aiconfig) (2.0.1)\n",
            "Collecting mccabe<0.8.0,>=0.7.0 (from flake8->python-aiconfig)\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting pycodestyle<2.12.0,>=2.11.0 (from flake8->python-aiconfig)\n",
            "  Downloading pycodestyle-2.11.1-py2.py3-none-any.whl (31 kB)\n",
            "Collecting pyflakes<3.2.0,>=3.1.0 (from flake8->python-aiconfig)\n",
            "  Downloading pyflakes-3.1.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-ai-generativelanguage==0.3.3 (from google-generativeai->python-aiconfig)\n",
            "  Downloading google_ai_generativelanguage-0.3.3-py3-none-any.whl (267 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.9/267.9 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from google-generativeai->python-aiconfig) (2.17.3)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai->python-aiconfig) (2.11.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai->python-aiconfig) (3.20.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.3.3->google-generativeai->python-aiconfig) (1.22.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->python-aiconfig) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->python-aiconfig) (2023.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->python-aiconfig) (6.0.1)\n",
            "Collecting PyMeta3>=0.5.1 (from pybars3->python-aiconfig)\n",
            "  Downloading PyMeta3-0.5.1.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->python-aiconfig) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->python-aiconfig) (1.3.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai->python-aiconfig) (1.61.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai->python-aiconfig) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai->python-aiconfig) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai->python-aiconfig) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai->python-aiconfig) (4.9)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai->python-aiconfig) (1.59.2)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai->python-aiconfig) (1.48.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai->python-aiconfig) (0.5.0)\n",
            "Building wheels for collected packages: pybars3, PyMeta3\n",
            "  Building wheel for pybars3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybars3: filename=pybars3-0.9.7-py3-none-any.whl size=14082 sha256=466c34958fd8c1100d12cd54987ea69ed40566dc043b1fe08b1b3643f4b4f27e\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/5b/65/505e94231d7dc278c9e0ddf8dbb1974cfb303eba742dbf55dd\n",
            "  Building wheel for PyMeta3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyMeta3: filename=PyMeta3-0.5.1-py3-none-any.whl size=16449 sha256=70c74c96b7127caa80140d85216359088f418fe5caae4f621cf01bf09c110198\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/ef/62/1d388a1576d871760164a1388632b29645c3f907cd009d6cb1\n",
            "Successfully built pybars3 PyMeta3\n",
            "Installing collected packages: PyMeta3, typing-extensions, result, requests, python-dotenv, pyflakes, pycodestyle, pybars3, pathspec, mypy-extensions, mccabe, h11, annotated-types, pydantic-core, huggingface-hub, httpcore, flake8, black, pydantic, httpx, openai, google-ai-generativelanguage, google-generativeai, python-aiconfig\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.13\n",
            "    Uninstalling pydantic-1.10.13:\n",
            "      Successfully uninstalled pydantic-1.10.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.30.0 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\n",
            "yfinance 0.2.31 requires requests>=2.31, but you have requests 2.30.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyMeta3-0.5.1 annotated-types-0.6.0 black-23.11.0 flake8-6.1.0 google-ai-generativelanguage-0.3.3 google-generativeai-0.2.2 h11-0.14.0 httpcore-1.0.2 httpx-0.25.1 huggingface-hub-0.19.4 mccabe-0.7.0 mypy-extensions-1.0.0 openai-1.3.2 pathspec-0.11.2 pybars3-0.9.7 pycodestyle-2.11.1 pydantic-2.5.1 pydantic-core-2.14.3 pyflakes-3.1.0 python-aiconfig-1.0.9 python-dotenv-1.0.0 requests-2.30.0 result-0.14.0 typing-extensions-4.8.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# !pip install openai python-aiconfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru_ujtI_-M8y",
        "outputId": "15532497-87bb-4057-c4b3-b79d4d02d474"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_parsers\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# import openai\n",
        "# import aiconfig\n",
        "# from google.colab import userdata\n",
        "# openai.api_key = userdata.get('OPENAI_API_KEY')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Non-Colab\n",
        "import json\n",
        "import openai\n",
        "openai.api_key = open(\"C:\\\\Users\\\\2time\\\\Projects\\\\secrets\\\\openai_api_key.txt\", 'r').read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxkHKfMLbTLN"
      },
      "source": [
        "## Function Calling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "x6rFM3Vpcs-D"
      },
      "outputs": [],
      "source": [
        "from pydantic import create_model\n",
        "from typing import Callable, List\n",
        "import inspect, json\n",
        "from inspect import Parameter\n",
        "def sums(a:int, b:int=1):\n",
        "    \"Adds a + b\"\n",
        "    return a + b\n",
        "def schema(f):\n",
        "    kw = {n:(o.annotation, ... if o.default==Parameter.empty else o.default)\n",
        "          for n,o in inspect.signature(f).parameters.items()}\n",
        "    s = create_model(f'Input for `{f.__name__}`', **kw).schema()\n",
        "    return dict(name=f.__name__, description=f.__doc__, parameters=s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ZST3nyXJbwEs"
      },
      "outputs": [],
      "source": [
        "def build_function_call_spec(functions: List[Callable]):\n",
        "    spec = json.load(open(\"function_calling_stub_aiconfig.json\", 'r'))\n",
        "    spec[\"prompts\"][0][\"metadata\"][\"model\"][\"settings\"][\"functions\"] = [schema(f) for f in functions]\n",
        "    return spec\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "fBN7ETp6bV5o"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import json\n",
        "import uuid\n",
        "from aiconfig import AIConfigRuntime\n",
        "from aiconfig import Prompt\n",
        "from aiconfig import PromptInput\n",
        "from aiconfig.model_parser import InferenceOptions\n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "async def function_calling(function_list):\n",
        "    function_call_spec = build_function_call_spec(function_list)\n",
        "    config = AIConfigRuntime.create(**function_call_spec)\n",
        "\n",
        "    params = {\n",
        "        \"book\": \"Where the Crawdads Sing\",\n",
        "    }\n",
        "\n",
        "    completionParams = await config.resolve(\"recommendBook\", params)\n",
        "\n",
        "    print(\"completionParams=\", end=\" \")\n",
        "    pprint(completionParams)\n",
        "\n",
        "    messages = completionParams[\"messages\"]\n",
        "    print(messages[0])\n",
        "    print(messages[1])\n",
        "    print()\n",
        "\n",
        "    promptToRun = \"recommendBook\"\n",
        "\n",
        "    inference_options = InferenceOptions(stream=True)\n",
        "\n",
        "    while True:\n",
        "        model_output = await config.run(promptToRun, params, inference_options)\n",
        "\n",
        "        output = model_output[0] if isinstance(model_output, list) else model_output\n",
        "\n",
        "        if output.output_type == \"error\":\n",
        "            print(f\"Error during inference: {output.ename}: {output.evalue}\")\n",
        "            return config\n",
        "\n",
        "        message = output.data\n",
        "\n",
        "        # If there is no function call, we're done and can exit this loop\n",
        "        if not message.get(\"function_call\", None):\n",
        "            return config\n",
        "\n",
        "        # If there is a function call, we generate a new message with the role 'function'.\n",
        "\n",
        "        result = await callFunction(message.get(\"function_call\"))\n",
        "\n",
        "        new_message = {\n",
        "            \"role\": \"function\",\n",
        "            \"name\": message[\"function_call\"][\"name\"],\n",
        "            \"content\": json.dumps(result),\n",
        "        }\n",
        "\n",
        "        promptToRun = f\"functionCallResult-{uuid.uuid4()}\"\n",
        "\n",
        "        existing_prompt = config.get_prompt(\"recommendBook\")\n",
        "\n",
        "        new_prompt = copy.deepcopy(existing_prompt)\n",
        "        new_prompt.name = promptToRun\n",
        "        new_prompt.input = PromptInput(**new_message)\n",
        "        new_prompt.outputs = []\n",
        "\n",
        "        config.add_prompt(new_prompt.name, new_prompt)\n",
        "\n",
        "        print(f\"{new_message}\\n\")\n",
        "\n",
        "\n",
        "db = [\n",
        "    {\n",
        "        \"id\": \"a1\",\n",
        "        \"name\": \"To Kill a Mockingbird\",\n",
        "        \"genre\": \"historical\",\n",
        "        \"description\": 'Compassionate, dramatic, and deeply moving, \"To Kill A Mockingbird\" takes readers to the roots of human behavior - to innocence and experience, kindness and cruelty, love and hatred, humor and pathos. Now with over 18 million copies in print and translated into forty languages, this regional story by a young Alabama woman claims universal appeal. Harper Lee always considered her book to be a simple love story. Today it is regarded as a masterpiece of American literature.',\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"a2\",\n",
        "        \"name\": \"All the Light We Cannot See\",\n",
        "        \"genre\": \"historical\",\n",
        "        \"description\": \"In a mining town in Germany, Werner Pfennig, an orphan, grows up with his younger sister, enchanted by a crude radio they find that brings them news and stories from places they have never seen or imagined. Werner becomes an expert at building and fixing these crucial new instruments and is enlisted to use his talent to track down the resistance. Deftly interweaving the lives of Marie-Laure and Werner, Doerr illuminates the ways, against all odds, people try to be good to one another.\",\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"a3\",\n",
        "        \"name\": \"Where the Crawdads Sing\",\n",
        "        \"genre\": \"historical\",\n",
        "        \"description\": \"\"\"For years, rumors of the “Marsh Girl” haunted Barkley Cove, a quiet fishing village. Kya Clark is barefoot and wild; unfit for polite society. So in late 1969, when the popular Chase Andrews is found dead, locals immediately suspect her.\n",
        "\n",
        "But Kya is not what they say. A born naturalist with just one day of school, she takes life's lessons from the land, learning the real ways of the world from the dishonest signals of fireflies. But while she has the skills to live in solitude forever, the time comes when she yearns to be touched and loved. Drawn to two young men from town, who are each intrigued by her wild beauty, Kya opens herself to a new and startling world—until the unthinkable happens.\"\"\",\n",
        "    },\n",
        "]\n",
        "\n",
        "\n",
        "async def list_items(genre: str):\n",
        "    \"\"\"list queries books by genre, and returns a list of names of books\"\"\"\n",
        "    # filter\n",
        "    items = [item for item in db if item[\"genre\"] == genre]\n",
        "    # map\n",
        "    return [{\"name\": item[\"name\"], \"id\": item[\"id\"]} for item in items]\n",
        "\n",
        "\n",
        "async def search(name: str):\n",
        "    \"\"\"search queries books by their name and returns a list of book names and their ids\"\"\"\n",
        "    # filter\n",
        "    items = [item for item in db if name in item[\"name\"]]\n",
        "    # map\n",
        "    return [{\"name\": item[\"name\"], \"id\": item[\"id\"]} for item in items]\n",
        "\n",
        "\n",
        "async def get(id: str):\n",
        "    \"\"\"get returns a book's detailed information based on the id of the book. Note that this does not accept names, and only IDs, which you can get by using search.\"\"\"\n",
        "    return [item for item in db if item[\"id\"] == id][0] or None\n",
        "\n",
        "\n",
        "async def callFunction(function_call):\n",
        "    args = function_call.get(\"arguments\", None)\n",
        "    args = json.loads(args) if args else None\n",
        "\n",
        "    if not args:\n",
        "        raise Exception(\"No arguments found\")\n",
        "\n",
        "    match function_call.get(\"name\"):\n",
        "        case \"list_items\":\n",
        "            return await list_items(args[\"genre\"])\n",
        "        case \"search\":\n",
        "            return await search(args[\"name\"])\n",
        "        case \"get\":\n",
        "            return await get(args[\"id\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "partial_spec = json.load(open(\"function_calling_stub_aiconfig.json\", 'r'))\n",
        "partial_spec[\"prompts\"][0][\"metadata\"][\"model\"][\"settings\"][\"functions\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\2time\\AppData\\Local\\Temp\\ipykernel_14432\\107065073.py:11: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
            "  s = create_model(f'Input for `{f.__name__}`', **kw).schema()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'name': 'function-call-demo',\n",
              " 'description': 'this is a demo AIConfig to show function calling using OpenAI',\n",
              " 'schema_version': 'latest',\n",
              " 'metadata': {},\n",
              " 'prompts': [{'name': 'recommendBook',\n",
              "   'input': {'role': 'user',\n",
              "    'content': 'I really enjoyed reading {{book}}, could you recommend me a book that is similar and tell me why?'},\n",
              "   'metadata': {'model': {'name': 'gpt-3.5-turbo',\n",
              "     'settings': {'model': 'gpt-3.5-turbo',\n",
              "      'functions': [{'name': 'list_items',\n",
              "        'description': 'list queries books by genre, and returns a list of names of books',\n",
              "        'parameters': {'properties': {'genre': {'title': 'Genre',\n",
              "           'type': 'string'}},\n",
              "         'required': ['genre'],\n",
              "         'title': 'Input for `list_items`',\n",
              "         'type': 'object'}},\n",
              "       {'name': 'search',\n",
              "        'description': 'search queries books by their name and returns a list of book names and their ids',\n",
              "        'parameters': {'properties': {'name': {'title': 'Name',\n",
              "           'type': 'string'}},\n",
              "         'required': ['name'],\n",
              "         'title': 'Input for `search`',\n",
              "         'type': 'object'}},\n",
              "       {'name': 'get',\n",
              "        'description': \"get returns a book's detailed information based on the id of the book. Note that this does not accept names, and only IDs, which you can get by using search.\",\n",
              "        'parameters': {'properties': {'id': {'title': 'Id', 'type': 'string'}},\n",
              "         'required': ['id'],\n",
              "         'title': 'Input for `get`',\n",
              "         'type': 'object'}}],\n",
              "      'system_prompt': {'role': 'system',\n",
              "       'content': 'Please use our book database, which you can access using functions to answer the following questions.'}}},\n",
              "    'parameters': {},\n",
              "    'remember_chat_context': True}}]}"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "function_call_spec = build_function_call_spec([list_items, search, get])\n",
        "function_call_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\2time\\AppData\\Local\\Temp\\ipykernel_14432\\107065073.py:11: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
            "  s = create_model(f'Input for `{f.__name__}`', **kw).schema()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "completionParams= {'functions': [{'description': 'list queries books by genre, and returns a '\n",
            "                               'list of names of books',\n",
            "                'name': 'list_items',\n",
            "                'parameters': {'properties': {'genre': {'title': 'Genre',\n",
            "                                                        'type': 'string'}},\n",
            "                               'required': ['genre'],\n",
            "                               'title': 'Input for `list_items`',\n",
            "                               'type': 'object'}},\n",
            "               {'description': 'search queries books by their name and returns '\n",
            "                               'a list of book names and their ids',\n",
            "                'name': 'search',\n",
            "                'parameters': {'properties': {'name': {'title': 'Name',\n",
            "                                                       'type': 'string'}},\n",
            "                               'required': ['name'],\n",
            "                               'title': 'Input for `search`',\n",
            "                               'type': 'object'}},\n",
            "               {'description': \"get returns a book's detailed information \"\n",
            "                               'based on the id of the book. Note that this '\n",
            "                               'does not accept names, and only IDs, which you '\n",
            "                               'can get by using search.',\n",
            "                'name': 'get',\n",
            "                'parameters': {'properties': {'id': {'title': 'Id',\n",
            "                                                     'type': 'string'}},\n",
            "                               'required': ['id'],\n",
            "                               'title': 'Input for `get`',\n",
            "                               'type': 'object'}}],\n",
            " 'messages': [{'content': 'Please use our book database, which you can access '\n",
            "                          'using functions to answer the following questions.',\n",
            "               'role': 'system'},\n",
            "              {'content': 'I really enjoyed reading Where the Crawdads Sing, '\n",
            "                          'could you recommend me a book that is similar and '\n",
            "                          'tell me why?',\n",
            "               'role': 'user'}],\n",
            " 'model': 'gpt-3.5-turbo'}\n",
            "{'content': 'Please use our book database, which you can access using functions to answer the following questions.', 'role': 'system'}\n",
            "{'content': 'I really enjoyed reading Where the Crawdads Sing, could you recommend me a book that is similar and tell me why?', 'role': 'user'}\n",
            "\n",
            "{'role': 'function', 'name': 'search', 'content': '[{\"name\": \"Where the Crawdads Sing\", \"id\": \"a3\"}]'}\n",
            "\n",
            "{'role': 'function', 'name': 'get', 'content': '{\"id\": \"a3\", \"name\": \"Where the Crawdads Sing\", \"genre\": \"historical\", \"description\": \"For years, rumors of the \\\\u201cMarsh Girl\\\\u201d haunted Barkley Cove, a quiet fishing village. Kya Clark is barefoot and wild; unfit for polite society. So in late 1969, when the popular Chase Andrews is found dead, locals immediately suspect her.\\\\n\\\\nBut Kya is not what they say. A born naturalist with just one day of school, she takes life\\'s lessons from the land, learning the real ways of the world from the dishonest signals of fireflies. But while she has the skills to live in solitude forever, the time comes when she yearns to be touched and loved. Drawn to two young men from town, who are each intrigued by her wild beauty, Kya opens herself to a new and startling world\\\\u2014until the unthinkable happens.\"}'}\n",
            "\n",
            "{'role': 'function', 'name': 'list_items', 'content': '[{\"name\": \"To Kill a Mockingbird\", \"id\": \"a1\"}, {\"name\": \"All the Light We Cannot See\", \"id\": \"a2\"}, {\"name\": \"Where the Crawdads Sing\", \"id\": \"a3\"}]'}\n",
            "\n",
            "I would recommend the book \"To Kill a Mockingbird\" as a similar book to \"Where the Crawdads Sing\". \n",
            "\n",
            "\"To Kill a Mockingbird\" is also a historical novel that explores themes of innocence, injustice, and the power of compassion. Like \"Where the Crawdads Sing\", it is set in a small Southern town and delves into the complexities of human nature and the impact of societal norms on individuals.\n",
            "\n",
            "Both books feature strong and unforgettable female protagonists who face adversity and navigate their way through difficult circumstances. These stories highlight the resilience and strength of these women as they confront the challenges of their environment.\n",
            "\n",
            "Overall, \"To Kill a Mockingbird\" shares similarities with \"Where the Crawdads Sing\" in terms of genre, themes, and compelling storytelling, making it a great recommendation for fans of the latter."
          ]
        }
      ],
      "source": [
        "book_search = await function_calling([list_items, search, get])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "emOUHVN2faSS",
        "outputId": "d708732a-644f-40fd-9ab1-cc8a0347d88c"
      },
      "outputs": [],
      "source": [
        "book_search.save(\"book_search.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpDwvL9Biymr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
