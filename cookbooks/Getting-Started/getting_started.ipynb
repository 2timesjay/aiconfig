{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNmnUZnUFzt3"
      },
      "source": [
        "# Installation and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sq9uM4ENFStR"
      },
      "outputs": [],
      "source": [
        "!pip install python-aiconfig\n",
        "!pip install openai==0.28.1\n",
        "from google.colab import userdata\n",
        "import openai\n",
        "\n",
        "openai.api_key = userdata.get('openai_api_key')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jacobjensen/.pyenv/versions/aiconfig/lib/python3.10/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_parsers\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "/home/jacobjensen/.pyenv/versions/aiconfig/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "#Import libraries\n",
        "import openai\n",
        "import os\n",
        "from aiconfig.Config import AIConfigRuntime\n",
        "\n",
        "# #Set the OpenAI key. The following code is specific for Google Colab\n",
        "# #We recommend using environment variables for setting the open ai key\n",
        "# from google.colab import userdata\n",
        "# openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "openai.api_key = open(\"/home/jacobjensen/secrets/openai_api_key.txt\", \"r\").read().strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FMlVH2bF4iN"
      },
      "source": [
        "# 1. Download AI Config `travel.aiconfig.json`\n",
        "Download the `travel.aiconfig.json` from [Getting Started](https://aiconfig.lastmileai.dev/docs/introduction/getting-started). Upload to your colab notebook and load (shown below).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "go9T1xivF4S2"
      },
      "outputs": [],
      "source": [
        "from aiconfig import AIConfigRuntime, InferenceOptions\n",
        "\n",
        "# Load the aiconfig. You can also use AIConfigRuntime.loadJSON({})\n",
        "config = AIConfigRuntime.load('travel.aiconfig.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqCchve9GINL"
      },
      "source": [
        "# 2. Run `get_activities` prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvAQbo70GLa0",
        "outputId": "25f0684e-6818-4026-df99-117479b4af37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatCompletionChunk(id='chatcmpl-8PtKzeIbkZ1SZvZyKUxaBeVxiQr36', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None), finish_reason=None, index=0)], created=1701181609, model='gpt-3.5-turbo-0613', object='chat.completion.chunk', system_fingerprint=None)\n",
            "[Choice(delta=ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None), finish_reason=None, index=0)]\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'ChoiceDelta' object has no attribute 'items'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m~/.pyenv/versions/aiconfig/lib/python3.10/site-packages/pydantic/main.py:753\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 753\u001b[0m     \u001b[39mreturn\u001b[39;00m pydantic_extra[item]\n\u001b[1;32m    754\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
            "\u001b[0;31mKeyError\u001b[0m: 'items'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m/home/jacobjensen/Projects/llms/aiconfig/cookbooks/Getting-Started/getting_started.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jacobjensen/Projects/llms/aiconfig/cookbooks/Getting-Started/getting_started.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mawait\u001b[39;00m config\u001b[39m.\u001b[39mrun(\u001b[39m\"\u001b[39m\u001b[39mget_activities\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/Projects/llms/aiconfig/python/src/aiconfig/Config.py:245\u001b[0m, in \u001b[0;36mAIConfigRuntime.run\u001b[0;34m(self, prompt_name, params, options, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m model_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_model_name(prompt_data)\n\u001b[1;32m    243\u001b[0m model_provider \u001b[39m=\u001b[39m AIConfigRuntime\u001b[39m.\u001b[39mget_model_parser(model_name)\n\u001b[0;32m--> 245\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m model_provider\u001b[39m.\u001b[39mrun(prompt_data, \u001b[39mself\u001b[39m, options, params, callback_manager \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    247\u001b[0m event \u001b[39m=\u001b[39m CallbackEvent(\u001b[39m\"\u001b[39m\u001b[39mon_run_complete\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m__name__\u001b[39m, {\u001b[39m\"\u001b[39m\u001b[39mresult\u001b[39m\u001b[39m\"\u001b[39m: response})\n\u001b[1;32m    248\u001b[0m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mrun_callbacks(event)\n",
            "File \u001b[0;32m~/Projects/llms/aiconfig/python/src/aiconfig/default_parsers/parameterized_model_parser.py:61\u001b[0m, in \u001b[0;36mParameterizedModelParser.run\u001b[0;34m(self, prompt, aiconfig, options, parameters, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_with_dependencies(prompt, aiconfig, options, parameters)\n\u001b[1;32m     60\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 61\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_inference(prompt, aiconfig, options, parameters)\n",
            "File \u001b[0;32m~/Projects/llms/aiconfig/python/src/aiconfig/default_parsers/openai.py:277\u001b[0m, in \u001b[0;36mOpenAIInference.run_inference\u001b[0;34m(self, prompt, aiconfig, options, parameters)\u001b[0m\n\u001b[1;32m    274\u001b[0m response \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mmodel_dump(exclude_none\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \\\n\u001b[1;32m    275\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(response, BaseModel) \u001b[39melse\u001b[39;00m response\n\u001b[1;32m    276\u001b[0m \u001b[39m# streaming only returns one chunk, one choice at a time (before 1.0.0). The order in which the choices are returned is not guaranteed.\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m messages \u001b[39m=\u001b[39m multi_choice_message_reducer(messages, chunk)\n\u001b[1;32m    279\u001b[0m \u001b[39mfor\u001b[39;00m i, choice \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(chunk[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m]):\n\u001b[1;32m    280\u001b[0m     index \u001b[39m=\u001b[39m choice\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/Projects/llms/aiconfig/python/src/aiconfig/default_parsers/openai.py:397\u001b[0m, in \u001b[0;36mmulti_choice_message_reducer\u001b[0;34m(messages, chunk)\u001b[0m\n\u001b[1;32m    395\u001b[0m     index \u001b[39m=\u001b[39m choice\u001b[39m.\u001b[39mindex\n\u001b[1;32m    396\u001b[0m     previous_message \u001b[39m=\u001b[39m messages\u001b[39m.\u001b[39mget(index, {})\n\u001b[0;32m--> 397\u001b[0m     updated_message \u001b[39m=\u001b[39m reduce(previous_message, choice\u001b[39m.\u001b[39;49mdelta)\n\u001b[1;32m    398\u001b[0m     messages[index] \u001b[39m=\u001b[39m updated_message\n\u001b[1;32m    400\u001b[0m \u001b[39mreturn\u001b[39;00m messages\n",
            "File \u001b[0;32m~/Projects/llms/aiconfig/python/src/aiconfig/default_parsers/openai.py:369\u001b[0m, in \u001b[0;36mreduce\u001b[0;34m(acc, delta)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreduce\u001b[39m(acc, delta):\n\u001b[1;32m    367\u001b[0m     acc \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(acc)\n\u001b[0;32m--> 369\u001b[0m     \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m delta\u001b[39m.\u001b[39;49mitems():\n\u001b[1;32m    370\u001b[0m         \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m acc:\n\u001b[1;32m    371\u001b[0m             \u001b[39m# If the key doesn't exist in 'acc', add it with the 'value'\u001b[39;00m\n\u001b[1;32m    372\u001b[0m             acc[key] \u001b[39m=\u001b[39m value\n",
            "File \u001b[0;32m~/.pyenv/versions/aiconfig/lib/python3.10/site-packages/pydantic/main.py:755\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[39mreturn\u001b[39;00m pydantic_extra[item]\n\u001b[1;32m    754\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m--> 755\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m object has no attribute \u001b[39m\u001b[39m{\u001b[39;00mitem\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n\u001b[1;32m    756\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    757\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m, item):\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ChoiceDelta' object has no attribute 'items'"
          ]
        }
      ],
      "source": [
        "await config.run(\"get_activities\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ8ddRVoHNOS"
      },
      "source": [
        "# 3. Enable streaming\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd6BFPGiHPJe",
        "outputId": "c036236b-ffe0-4542-a58f-79545c479d5b"
      },
      "outputs": [],
      "source": [
        "from aiconfig import AIConfigRuntime, InferenceOptions\n",
        "\n",
        "# Load the aiconfig. You can also use AIConfigRuntime.loadJSON({})\n",
        "config = AIConfigRuntime.load('travel.aiconfig.json')\n",
        "\n",
        "# Run a single prompt (with streaming)\n",
        "inference_options = InferenceOptions(stream=True)\n",
        "await config.run(\"get_activities\", options=inference_options)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Fgj5w85Sbch"
      },
      "source": [
        "# 4. Run `gen_itinerary` prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49xN8OiqSeMX",
        "outputId": "edb32c2b-7bb9-475e-fd4b-0a1d510952e4"
      },
      "outputs": [],
      "source": [
        "inference_options = InferenceOptions(stream=True)\n",
        "await config.run(\n",
        "    \"gen_itinerary\",\n",
        "    params={\"order_by\": \"duration\"},\n",
        "    options=inference_options,\n",
        "    run_with_dependencies=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9deFcBK55yN"
      },
      "source": [
        "# 5. Save the AIConfig with outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BR4-nGxSth7"
      },
      "outputs": [],
      "source": [
        "# Save the aiconfig to disk. and serialize outputs from the model run\n",
        "config.save('updated.aiconfig.json', include_outputs=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLiElYyC6DB-"
      },
      "source": [
        "# 6. Open the AIConfig in AI Workbook Playground\n",
        "1. Download `updated.aiconfig.json`.\n",
        "2. Go to https://lastmileai.dev.\n",
        "3. Go to Workbooks page: https://lastmileai.dev/workbooks.\n",
        "4. Click dropdown '+New Workbook' and select 'Create from AIConfig'\n",
        "5. Upload `updated.aiconfig.json`.\n",
        "\n",
        "Try out the workbook playground here: [NYC Travel Workbook](https://lastmileai.dev/workbooks/clooqs3p200kkpe53u6n2rhr9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLpVz4L56GIY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
